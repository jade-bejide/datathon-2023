The F1 score is the harmonic mean of the precision and recall.
It combines the precision and recall scores of a model into one metric and computes how many times a model made a correct prediction
across the entire dataset.

-------
Definitions:

Precision is the fraction of true positive examples among the examples that the model classified as positive. In other words, the number of true positives divided by the number of false positives plus true positives.

Recall, also known as sensitivity, is the fraction of examples classified as positive, among the total number of positive examples. In other words, the number of true positives divided by the number of true positives plus false negatives.

The harmonic mean is defined as the reciprocal of the arithmetic mean
of the reciprocals.

https://www.quora.com/In-Machine-Learning-what-does-it-mean-in-simple-terms-that-the-F1-score-is-the-harmonic-mean-of-precision-and-recall

-------

ROC AUC score:

Compute Area Under the Receiver Operating Characteristic Curve
(ROC AUC) from prediction scores.

It tells how much the model is capable of distinguishing between classes based off of the false positive rate and true positive rate.
