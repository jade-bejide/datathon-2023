{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15937fbf",
   "metadata": {},
   "source": [
    "# BDSS Datathon 2023 - work in progress\n",
    "\n",
    "### Jupyter Notebook\n",
    "\n",
    "Python can be run on [Jupyter Notebook](http://jupyter.org/) too.\n",
    "\n",
    "Jupyter Notebook is a computing environment supporting various programing languages (Python, R, Lua, etc.) through the concept of kernels.  \n",
    "It allows you to enrich your code with complex comments formatted in Markdown and $\\LaTeX$, as well as to place the results of your computation right below your code. Beside, it has all the features provided by the ipython interpreter, like tab auto-completion. \n",
    "\n",
    "Jupyter Notebook runs as a web server. To run this lab sheet navigate to the folder containing the file `labsheet1.ipynb` and run Jupyter:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fb2c67",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e687373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "# notebook\n",
    "import matplotlib.pylab as pylab\n",
    "pylab.rcParams['figure.figsize'] = (16.0, 12.0)\n",
    "pylab.rcParams['font.size'] = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32bffe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import xgboost as xgb\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2860cfb4",
   "metadata": {},
   "source": [
    "### Feature Selection and Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d43d803",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['accident_reference', 'vehicle_reference_x', 'casualty_reference',\n",
      "       'casualty_class', 'sex_of_casualty', 'age_of_casualty',\n",
      "       'age_band_of_casualty', 'casualty_severity', 'pedestrian_location',\n",
      "       'pedestrian_movement', 'car_passenger', 'bus_or_coach_passenger',\n",
      "       'pedestrian_road_maintenance_worker', 'casualty_type',\n",
      "       'casualty_home_area_type', 'casualty_imd_decile', 'lsoa_of_casualty',\n",
      "       'vehicle_reference_y', 'vehicle_type', 'towing_and_articulation',\n",
      "       'vehicle_manoeuvre', 'vehicle_direction_from', 'vehicle_direction_to',\n",
      "       'vehicle_location_restricted_lane', 'junction_location',\n",
      "       'skidding_and_overturning', 'hit_object_in_carriageway',\n",
      "       'vehicle_leaving_carriageway', 'hit_object_off_carriageway',\n",
      "       'first_point_of_impact', 'vehicle_left_hand_drive',\n",
      "       'journey_purpose_of_driver', 'sex_of_driver', 'age_of_driver',\n",
      "       'age_band_of_driver', 'engine_capacity_cc', 'propulsion_code',\n",
      "       'age_of_vehicle', 'generic_make_model', 'driver_imd_decile',\n",
      "       'driver_home_area_type', 'lsoa_of_driver'],\n",
      "      dtype='object')\n",
      "42\n",
      "['accident_reference', 'vehicle_reference_x', 'casualty_reference', 'casualty_class', 'sex_of_casualty', 'age_of_casualty', 'age_band_of_casualty', 'casualty_severity', 'pedestrian_location', 'pedestrian_movement', 'car_passenger', 'bus_or_coach_passenger', 'pedestrian_road_maintenance_worker', 'casualty_type', 'casualty_home_area_type', 'casualty_imd_decile', 'lsoa_of_casualty', 'vehicle_reference_y', 'vehicle_type', 'towing_and_articulation', 'vehicle_manoeuvre', 'vehicle_direction_from', 'vehicle_direction_to', 'vehicle_location_restricted_lane', 'junction_location', 'skidding_and_overturning', 'hit_object_in_carriageway', 'vehicle_leaving_carriageway', 'hit_object_off_carriageway', 'first_point_of_impact', 'vehicle_left_hand_drive', 'journey_purpose_of_driver', 'sex_of_driver', 'age_of_driver', 'age_band_of_driver', 'engine_capacity_cc', 'propulsion_code', 'age_of_vehicle', 'generic_make_model', 'driver_imd_decile', 'driver_home_area_type', 'lsoa_of_driver']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "casualty_data = pd.read_csv(\"casualty_train.csv\", delimiter=\",\")\n",
    "vehicle_data = pd.read_csv(\"vehicle_train.csv\", delimiter=\",\")\n",
    "\n",
    "all_data = pd.merge(casualty_data, vehicle_data, on='accident_reference', how='outer')\n",
    "print(all_data.columns)\n",
    "print(len(all_data.columns))\n",
    "print(list(all_data.columns))\n",
    "\n",
    "# print(\"Features\")\n",
    "# print(casualty_data.columns)\n",
    "# print(\"=====\")\n",
    "\n",
    "features = list(all_data.columns)\n",
    "\n",
    "def fieldByAccidentCode(code, field):\n",
    "    field_data = all_data.loc[:, field]\n",
    "    final = {}\n",
    "    \n",
    "    for i in range(len(field_data)):\n",
    "        key = field_data[i]\n",
    "        if all_data[\"casualty_severity\"][i] == code:\n",
    "            if key not in final: final[key] = 0\n",
    "            else: final[key] += 1\n",
    "            \n",
    "    return final\n",
    "\n",
    "def getBasicStats(field):\n",
    "    field_data = all_data.loc[:, field]\n",
    "    \n",
    "    print(\"Mean:\", field_data.mean())\n",
    "    print(\"Standard Deviation:\", field_data.std())\n",
    "    print(\"Variance:\", field_data.var())\n",
    "    \n",
    "    print(\"Modal:\", field_data.mode())\n",
    "    print(\"Median:\", field_data.median())\n",
    "    \n",
    "    \n",
    "def constructBarChar(data):\n",
    "    keys = data.keys()\n",
    "    vals = data.values()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(keys, vals)\n",
    "#     ax.set_xlabel(\"Age\")\n",
    "#     ax.set_ylabel(\"Number of accidents\")\n",
    "\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "count = 0\n",
    "ignore = [\"lsoa_of_casualty\", \"generic_make_model\", \"lsoa_of_driver\"]\n",
    "# for feature in list(all_data.columns):\n",
    "#     print(feature.upper())\n",
    "#     if count == 0 or feature in ignore:\n",
    "#         count += 1\n",
    "#         continue\n",
    "        \n",
    "#     try: \n",
    "#         getBasicStats(feature)\n",
    "#     except: \n",
    "#         pass\n",
    "    \n",
    "#     print(\"\\n\\n\")\n",
    "    \n",
    "#     one_1 = fieldByAccidentCode(1, feature)\n",
    "#     one_2 = fieldByAccidentCode(2, feature)\n",
    "#     for key in one_1:\n",
    "#         if key in one_2: one_1[key] += one_2[key]\n",
    "        \n",
    "#     for key in one_2:\n",
    "#         if key not in one_1: one_1[key] = one_2[key]\n",
    "            \n",
    "#     one = one_1\n",
    "#     constructBarChar(one)\n",
    "#     plt.savefig(feature + \"_1.png\")\n",
    "#     two = fieldByAccidentCode(3, feature)\n",
    "#     constructBarChar(two)\n",
    "#     plt.savefig(feature + \"_2.png\")\n",
    "        \n",
    "        \n",
    "        \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ed01a5",
   "metadata": {},
   "source": [
    "### Training and modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67175cf8",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True]))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True]))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mall_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcasuality_severity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m all_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcasuality_severity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3804\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m         \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m         \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3809\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3810\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m \u001b[38;5;66;03m# GH#42269\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5925\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5921\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   5922\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5923\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5924\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5925\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True]))"
     ]
    }
   ],
   "source": [
    "X = all_data[:, all_data.columns != \"casuality_severity\"]\n",
    "y = all_data[\"casuality_severity\"]\n",
    "\n",
    "for index in range(len(y)):\n",
    "    if y[index] == 2: y[index] = 1\n",
    "    if y[index] == 3: y[index] = 2\n",
    "\n",
    "standardizer = StandardScaler()\n",
    "X = standardizer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.25, random_state=0)\n",
    "\n",
    "models = {}\n",
    "models['Logistic Regression'] = LogisticRegression()\n",
    "models['Support Vector Machines'] = LinearSVC()\n",
    "models['Decision Trees'] = DecisionTreeClassifier()\n",
    "models['Random Forest'] = RandomForestClassifier()\n",
    "models['Naive Bayes'] = GaussianNB()\n",
    "models['K-Nearest Neighbor'] = KNeighborsClassifier()\n",
    "models['XGBoost'] = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "\n",
    "accuracy, precision, recall, roc, f1 = {}, {}, {}, {}, {}\n",
    "\n",
    "for key in models.keys():\n",
    "    models[key].fit(X_train, y_train)\n",
    "\n",
    "    predictions = models[key].predict(X_test)\n",
    "\n",
    "    accuracy[key] = accuracy_score(predictions, y_test)\n",
    "    precision[key] = precision_score(predictions, y_test)\n",
    "    recall[key] = recall_score(predictions, y_test)\n",
    "    roc[key] = roc_auc_score(predictions, y_test)\n",
    "    f1[key] = f1_score(predictions, y_test)\n",
    "\n",
    "all_data_model = pd.DataFrame(index=models.keys(), columns=['Accuracy', 'Precision', 'Recall', 'Roc', 'F1', \"Summary\"])\n",
    "\n",
    "summary = {key: 0.5*(roc.get(key, 0) + f1.get(key, 0))\n",
    "          for key in set(roc) | set(f1)}\n",
    "\n",
    "all_data_model['Accuracy'] = accuracy.values()\n",
    "all_data_model['Precision'] = precision.values()\n",
    "all_data_model['Recall'] = recall.values()\n",
    "all_data_model['Roc'] = roc.values()\n",
    "all_data_model['F1'] = f1.values()\n",
    "all_data_model['Summary'] = summary.values()\n",
    "\n",
    "all_data_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
